{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "205274ec-7603-4a23-a402-8c24727f4f29",
   "metadata": {},
   "source": [
    "Demonstration/proof-of-concept code to take a document from an existing instance of eScriptorium and extract images of all the letters for palaeographical analysis.\n",
    "The code assumes the following:\n",
    "- You must have an account on an instance of [eScriptorium](https://escriptorium.readthedocs.io).\n",
    "- You must set the URL of your specific instance of eScriptorium in the variable `base_url` below.\n",
    "- You must have a document already in that instance and already transcribed automatically **without any manual correction**. The code will list available transcriptions using their names as stored in eScriptorium and ask which one you wish to use. Note that it will not offer any manual transcriptions.\n",
    "- You must know your API key (if not see https://escriptorium.readthedocs.io/en/latest/users/#review-and-edit-your-profile), and it is recommended that you set this as an environment variable using `export ESCRIPTORIUM_KEY={key value}` (for Linux/Mac) on the command line. Otherwise the code will ask you for this API key when you run the relevant cell. **You must exercise caution here to make sure that your key is not left visible in the notebook**, as it will be if you put it directly in the code, or if you enter it into the Jupyter input field and then don't clear the cells. **If you do leave it there then anyone who has access to the code will also effectively have your password to eScriptorium.**\n",
    "- You must know the ID number (pk) of the document you want to analyse, and this should be stored in the `doc_id` variable below. The easiest way to find this is to go to your document in eScriptorium and find the number in the URL after 'document' (e.g. for https://msia.escriptorium.fr/document/4982/images/ it would be 4982).\n",
    "- For the first part of the notebook you must also pick one page (image) for analysis from your document and put the relevant ID in the `part_id` variable below. Again you can get this from the url of your page in eScriptorium (it will be the second number after the doc id). At the end of the notebook you will analyse an entire document rather than just one page, but it's always better to start with a sample to make sure that you understand what it does and that it does what you want.\n",
    "\n",
    "Peter Stokes, EPHE-PSL, March 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932aef0-5ad8-4320-bbb6-a96e228219e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from requests.compat import urljoin\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203eb79b-4b5b-4cc6-ba43-077b91ca498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default verbose setting (can be overridden as required)\n",
    "isVerbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37949902-503a-41d3-9f44-d696605b0d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up authentication headers to access eScriptorium (see explanation above)\n",
    "\n",
    "api_token = os.getenv('ESCRIPTORIUM_KEY')\n",
    "\n",
    "if not(api_token):\n",
    "    api_token = input(\"No ESCRIPTORIUM_KEY env variable found. Please enter your key here:\")\n",
    "    \n",
    "headers = {'Content-type':'application/json', 'Accept':'application/json', 'Authorization': f'Token {api_token}'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f85ffb-f744-4622-a0d6-341de7289d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THESE VALUES according to your instance of eScriptorium, and the ID of the document and page you want to use.\n",
    "# See above for details.\n",
    "\n",
    "base_url = \"https://msia.escriptorium.fr/api/\"\n",
    "\n",
    "# Capitoli dei frati\n",
    "#doc_id = 3048\n",
    "#part_id = 559323\n",
    "\n",
    "# St Gallen MS\n",
    "#doc_id = 2913\n",
    "#part_id = 544917\n",
    "\n",
    "doc_id = 2917\n",
    "part_id = 545037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3452e4da-f36c-47fc-9fbd-3ec4943000a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to get all the elements in a page of JSON results from the API\n",
    "\n",
    "def get_page(part_url, page=1, verbose=isVerbose):\n",
    "    url = urljoin(part_url, '?page=%d' % page)\n",
    "\n",
    "    if verbose:\n",
    "        print('fetching', url)\n",
    "        \n",
    "    res = requests.get(url, headers=headers)\n",
    "    try:\n",
    "        data = res.json()\n",
    "    except json.decoder.JSONDecodeError as e:\n",
    "        print(res)\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6db6fc-1cfd-4260-9656-f6163bc21fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to get all the pages of results from the API\n",
    "# Note that 'page' here refers to paginated API results and has nothing to do with pages of a document!\n",
    "\n",
    "def get_paged_elements(element_url):\n",
    "    elems = []\n",
    "\n",
    "    page_no = 0\n",
    "    has_next_page = True\n",
    "\n",
    "    while has_next_page:\n",
    "        page_no += 1\n",
    "        data = get_page(element_url, page_no)\n",
    "        for part in data['results']:\n",
    "            elems.append(part)\n",
    "        has_next_page = data['next']\n",
    "            \n",
    "    return(elems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe7311c-3dbf-435a-9780-820c1bd4b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to download the image of a given document and part\n",
    "\n",
    "def get_image(doc_nu, part_nu, verbose=isVerbose):\n",
    "    part_data = get_page(urljoin(base_url, f\"documents/{doc_nu}/parts/{part_nu}/\"))\n",
    "    \n",
    "    im_addr = base_url + '..' + part_data['image']['uri']\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Image found at\", im_addr)\n",
    "    \n",
    "    im = io.imread(im_addr)\n",
    "\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50754219-4595-4975-9744-d3e5a6bda075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to get all the transcription lines for a given document, part (image) and transcription\n",
    "\n",
    "def get_transcriptions(doc_nu, part_nu, transcr_nu, verbose=isVerbose):\n",
    "    tr_data = get_paged_elements(urljoin(base_url, f\"documents/{doc_nu}/parts/{part_nu}/transcriptions/\"))\n",
    "    \n",
    "    transcriptions = []\n",
    "    for t in tr_data:\n",
    "        if t['transcription'] == transcr_nu:\n",
    "            transcriptions.append(t)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nFound {len(transcriptions)} lines for this transcription:\")\n",
    "        print(\" / \".join([t['content'] for t in transcriptions]))\n",
    "\n",
    "    return transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688b5b1-adae-40d3-b951-f79fdee36288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out a character image based on its position from the automatic transcription (the kraken cuts).\n",
    "# Note that the kraken results are only the approximate position, as it's not an OCR system (it doesn't specifically identify characters),\n",
    "# so we need to fiddle a bit to get useful coordinates.\n",
    "# Normally the vertical coordinates are pretty good but the horizontal ones are much too small, so\n",
    "# try to infer position based on the midpoint between the kraken cuts of this and the previous and following characters.\n",
    "# Also add a bit of margin, assuming that it's better to have too big cuts than too small ones.\n",
    "# TODO: better to have fixed-size images (will see why in next step)\n",
    "\n",
    "def get_graph_image(line_graphs, g_idx, img, verbose=isVerbose):\n",
    "    g = line_graphs[g_idx]\n",
    "\n",
    "    # If we don't have a regular box for polygon then we just leave it for now\n",
    "    if len(g['poly']) != 4:\n",
    "        return None\n",
    "\n",
    "    y_min = g['poly'][0][1]\n",
    "    y_max = g['poly'][1][1]\n",
    "\n",
    "    # Look for midpoint between this and the previous cut, unless this is the first character in the line\n",
    "    if (g_idx > 0) and len(line_graphs[g_idx-1]['poly']) >= 4:\n",
    "        x_min = (g['poly'][0][0] + line_graphs[g_idx-1]['poly'][3][0]) // 2\n",
    "    else:\n",
    "        x_min = g['poly'][0][0]\n",
    "\n",
    "    # Look for midpoint between this and the next cut, unless this is the last character in the line\n",
    "    if (g_idx < len(line_graphs) - 1):\n",
    "        x_max = (g['poly'][3][0] + line_graphs[g_idx+1]['poly'][0][0]) // 2\n",
    "    else:\n",
    "        x_max = g['poly'][3][0]\n",
    "\n",
    "    # Add some horizontal margin for good measure\n",
    "    x_min -= (x_max - x_min) // 3\n",
    "    x_max += (x_max - x_min) // 3\n",
    "\n",
    "    if verbose:\n",
    "        print(g['c'], x_min, y_min, x_max, y_max)\n",
    "\n",
    "    return img[y_min:y_max, x_min:x_max, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990d8b82-05c4-42ee-a525-144411975359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get all character images from a given set of transcriptions (normally lines from a given page)\n",
    "# Adds the character images to an existing dictionary keyed to the character\n",
    "\n",
    "def get_char_imgs(transcriptions, char_imgs, img, verbose=isVerbose):\n",
    "    \n",
    "    for l in transcriptions:\n",
    "        for idx, g in enumerate(l['graphs']):\n",
    "            newchar = g['c']\n",
    "            newim = get_graph_image(l['graphs'], idx, img)\n",
    "            \n",
    "            if newchar in char_imgs:\n",
    "                char_imgs[newchar].append(newim)\n",
    "            else:\n",
    "                char_imgs[newchar] = [newim]\n",
    "    return char_imgs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e4984-889f-4df6-bcd1-12b162cecba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a list of images in a grid with a set number of columns.\n",
    "# Intended to be used for a list of images of letters (graphs), though could be used for any list of images.\n",
    "\n",
    "def plot_chars(imgs, cols=12):\n",
    "    # Number of images\n",
    "    num_images = len(imgs)\n",
    "    if num_images == 0:\n",
    "        print(\"No character images found\")\n",
    "        return\n",
    "    \n",
    "    # Determine the number of rows necessary for the given number of images and columns\n",
    "    rows  = num_images // cols + 1\n",
    "    \n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols, rows+1))\n",
    "    \n",
    "    # Flatten the axes array for easy iteration\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Iterate over the images and corresponding axes to display each image\n",
    "    # Be careful: we can sometimes have zero-width images\n",
    "    for i in range(num_images):\n",
    "        if (imgs[i] is not None) and (len(imgs[i]) > 0):\n",
    "            axes[i].imshow(imgs[i])\n",
    "            axes[i].axis('off')  # Hide the axis\n",
    "    \n",
    "    # Hide any remaining empty subplots\n",
    "    for j in range(num_images, rows * cols):\n",
    "        axes[j].axis('off')\n",
    "    \n",
    "    # Display the grid of images\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"doc{doc_id}.jpg\")\n",
    "    plt.show()\n",
    "    \n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ff0b93-0d84-4e91-a853-ddb51f0b4e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the character images for a given page and store in a dictionary keyed to the character\n",
    "\n",
    "def get_chars_per_page(doc_id, part_id, transcr_id, verbose=isVerbose):\n",
    "    img = get_image(doc_id, part_id)\n",
    "    trans = get_transcriptions(doc_id, part_id, transcr_id)\n",
    "    \n",
    "    char_imgs = {}\n",
    "    return get_char_imgs(trans, char_imgs, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6005159-0def-4fb0-a731-da44f69b34bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of transcriptions and ask the user which one they want\n",
    "# Assume we only have one page of transcriptions.\n",
    "# Only include transcriptions which have an average confidence, assuming that these should be kraken generated.\n",
    "\n",
    "def select_transcription(doc_id):\n",
    "    transcr_list_url = urljoin(base_url, f\"documents/{doc_id}/transcriptions/\")\n",
    "    \n",
    "    transcr_full_list = get_page(transcr_list_url)\n",
    "    transcr_list = [t for t in transcr_full_list if t['avg_confidence'] and not t['archived']]\n",
    "    \n",
    "    print(\"Please select one of the following transcriptions by numer in the list (0, 2, 3...):\")\n",
    "    for idx, t in enumerate(transcr_list):\n",
    "        print(f\"  {idx}. {t['name']}\")\n",
    "    \n",
    "    trans_idx = int(input(\"\\nTranscription no.\"))\n",
    "    \n",
    "    if trans_idx in list(range(len(transcr_list))):\n",
    "        transcr_id = int(transcr_list[trans_idx]['pk'])\n",
    "        print(f\"Transcription id. {transcr_id} selected\")\n",
    "    else:\n",
    "        transcr_id = None\n",
    "        print(f\"Can't find selected transcript\")\n",
    "\n",
    "    return transcr_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3dae45-959a-44d5-8a36-7ba8fcedc545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the user for the transcription and then load all the graph images for the selected page into memory...\n",
    "\n",
    "transcr_id = select_transcription(doc_id)\n",
    "char_imgs = get_chars_per_page(doc_id, part_id, transcr_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faabef0-f512-4145-9221-5f4ffc0fe1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... and show the results for a character\n",
    "\n",
    "plot_chars(char_imgs['&'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d9452-586f-4570-a78c-4a9051da67ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now use get_paged_elements to loop through all the document parts and generate images for the entire document\n",
    "# Storing all the images in memory may be an issue here, so will probably need something more sophisticated for larger documents\n",
    "\n",
    "# First get all the part records for the document and filter out those parts which don't have the relevant transcription\n",
    "#doc_id = 4982\n",
    "doc_id = 2917\n",
    "transcr_id = select_transcription(doc_id)\n",
    "\n",
    "part_list = get_paged_elements(urljoin(base_url, f\"documents/{doc_id}/parts/\"))\n",
    "part_list_transcribed = [p for p in part_list if p['transcription_progress']==100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b3251d-d9b6-4da0-a6a4-1e8ebed26769",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now go through all the parts, extract the cuts and store them in memory\n",
    "# Note this mixes everything indiscriminately; we may prefer to keep the cuts by page so we can find them afterwards\n",
    "\n",
    "full_char_dict = {}\n",
    "\n",
    "for p in part_list_transcribed:\n",
    "    print(f\"Processing page {p['title']} ({p['pk']})\")\n",
    "    try:\n",
    "        tempdict = get_chars_per_page(doc_id, int(p['pk']), transcr_id)\n",
    "        \n",
    "        for key in tempdict:\n",
    "            if key in full_char_dict:\n",
    "                full_char_dict[key].extend(tempdict[key])\n",
    "            else:\n",
    "                full_char_dict[key] = tempdict[key]\n",
    "    except Exception as e:\n",
    "        # Catch any exception and print the error message\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f85fad-3144-441d-9da3-a6b9068ac278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test by taking a character\n",
    "char = 'a'\n",
    "samplesize = 1000\n",
    "\n",
    "print(f\"Found {len(full_char_dict[char])} sampes of character {char}; showing first {samplesize}\")\n",
    "\n",
    "theplot = plot_chars(full_char_dict[char][0:samplesize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550ac6e5-76d9-4fc0-9075-363e204cfa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now do the same but this time save the images into a subfolder by the identified character for later processing\n",
    "# Name the image by docid, partid, character then incremental number. This way we can find the character in the page relatively easily\n",
    "# Note that the OS probably isn't case sensitive for folder names, so minuscule and majuscule forms will be mixed.\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "output_path = os.path.join(os.path.expanduser('~'), 'Image_data', 'escr_chars', str(doc_id))\n",
    "\n",
    "if not os.path.exists(output_path):\n",
    "        os.makedirs(output_path)\n",
    "\n",
    "for p in part_list_transcribed:\n",
    "    print(f\"Processing page {p['title']} ({p['pk']})\")\n",
    "    try:\n",
    "        char_dict = get_chars_per_page(doc_id, int(p['pk']), transcr_id)\n",
    "    except Exception as e:\n",
    "        # Catch any exception and print the error message\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    \n",
    "    for key in char_dict:\n",
    "        subdir = os.path.join(output_path, key)\n",
    "        if not os.path.exists(subdir):\n",
    "            os.makedirs(subdir)\n",
    "        try:\n",
    "            for idx, char in enumerate(char_dict[key]):\n",
    "                img = Image.fromarray(char)\n",
    "                img.save(os.path.join(subdir, f\"char-{doc_id}-{p['pk']}-{idx}.png\"))\n",
    "                \n",
    "        except Exception as e:\n",
    "            # Catch any exception and print the error message\n",
    "            print(f\"An error occurred: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
