{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "205274ec-7603-4a23-a402-8c24727f4f29",
   "metadata": {},
   "source": [
    "Code to take a document from an existing instance of eScriptorium and extract images of all the letters for palaeographical analysis.\n",
    "The code assumes the following:\n",
    "- You must have an account on an instance of [eScriptorium](https://escriptorium.readthedocs.io).\n",
    "- You must set the URL of your specific instance of eScriptorium in the variable `base_url` below.\n",
    "- You must have a document already in that instance and already transcribed automatically **without any manual correction**. The code will list available transcriptions using their names as stored in eScriptorium and ask which one you wish to use. Note that it will not offer any manual transcriptions.\n",
    "- You must know your API key (if not see https://escriptorium.readthedocs.io/en/latest/users/#review-and-edit-your-profile), and it is recommended that you set this as an environment variable using `export ESCRIPTORIUM_KEY={key value}` (for Linux/Mac) on the command line. Otherwise the code will ask you for this API key when you run the relevant cell. **You must exercise caution here to make sure that your key is not left visible in the notebook**, as it will be if you put it directly in the code, or if you enter it into the Jupyter input field and then don't clear the cells. If you do leave it there then anyone who has access to the code will also effectively have your password to eScriptorium.\n",
    "- You must know the ID number (pk) of the document you want to analyse, and this should be stored in the `doc_id` variable below. The easiest way to find this is to go to your document in eScriptorium and find the number in the URL after 'document' (e.g. for https://msia.escriptorium.fr/document/4982/images/ it would be 4982).\n",
    "- For now you must also pick one page (image) for analysis from your document and put the relevant ID in the `part_id` variable below. Again you can get this from the url of your page in eScriptorium (it will be the second number after the doc id).\n",
    "\n",
    "Peter Stokes, EPHE-PSL, March 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932aef0-5ad8-4320-bbb6-a96e228219e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from requests.compat import urljoin\n",
    "from skimage import io\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203eb79b-4b5b-4cc6-ba43-077b91ca498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default verbose setting (can be overridden as required)\n",
    "isVerbose = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37949902-503a-41d3-9f44-d696605b0d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up authentication headers to access eScriptorium\n",
    "\n",
    "api_token = os.getenv('ESCRIPTORIUM_KEY')\n",
    "\n",
    "if not(api_token):\n",
    "    api_token = input(\"No ESCRIPTORIUM_KEY env variable set; please enter your key here:\")\n",
    "    \n",
    "headers = {'Content-type':'application/json', 'Accept':'application/json', 'Authorization': f'Token {api_token}'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f85ffb-f744-4622-a0d6-341de7289d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHANGE THESE VALUES according to your instance of eScriptorium, and the document and transcription you want to use.\n",
    "# See above for details.\n",
    "\n",
    "base_url = \"https://msia.escriptorium.fr/api/\"\n",
    "\n",
    "# Capitoli dei frati\n",
    "#doc_id = 3048\n",
    "#part_id = 559323\n",
    "\n",
    "# St Gallen MS\n",
    "doc_id = 2913\n",
    "part_id = 544917"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3452e4da-f36c-47fc-9fbd-3ec4943000a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to get all the elements in a page of JSON results from the API\n",
    "\n",
    "def get_page(part_url, page=1, verbose=isVerbose):\n",
    "    url = urljoin(part_url, '?page=%d' % page)\n",
    "\n",
    "    if verbose:\n",
    "        print('fetching', url)\n",
    "        \n",
    "    res = requests.get(url, headers=headers)\n",
    "    try:\n",
    "        data = res.json()\n",
    "    except json.decoder.JSONDecodeError as e:\n",
    "        print(res)\n",
    "    else:\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6db6fc-1cfd-4260-9656-f6163bc21fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to get all the pages of results from the API\n",
    "# Note that 'page' here refers to paginated API results and has nothing to do with pages of a document!\n",
    "\n",
    "def get_paged_elements(element_url):\n",
    "    elems = []\n",
    "\n",
    "    page_no = 0\n",
    "    has_next_page = True\n",
    "\n",
    "    while has_next_page:\n",
    "        page_no += 1\n",
    "        data = get_page(element_url, page_no)\n",
    "        for part in data['results']:\n",
    "            elems.append(part)\n",
    "        has_next_page = data['next']\n",
    "            \n",
    "    return(elems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe7311c-3dbf-435a-9780-820c1bd4b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to download the image of a given document and part\n",
    "\n",
    "def get_image(doc_nu, part_nu, verbose=isVerbose):\n",
    "    part_data = get_page(urljoin(base_url, f\"documents/{doc_nu}/parts/{part_nu}/\"))\n",
    "    \n",
    "    im_addr = base_url + '..' + part_data['image']['uri']\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Image found at\", im_addr)\n",
    "    \n",
    "    im = io.imread(im_addr)\n",
    "\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50754219-4595-4975-9744-d3e5a6bda075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to get all the transcription lines for a given document, part (image) and transcription\n",
    "\n",
    "def get_transcriptions(doc_nu, part_nu, transcr_nu, verbose=isVerbose):\n",
    "    tr_data = get_paged_elements(urljoin(base_url, f\"documents/{doc_nu}/parts/{part_nu}/transcriptions/\"))\n",
    "    \n",
    "    transcriptions = []\n",
    "    for t in tr_data:\n",
    "        if t['transcription'] == transcr_nu:\n",
    "            transcriptions.append(t)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"\\nFound {len(transcriptions)} lines for this transcription:\")\n",
    "        print(\" / \".join([t['content'] for t in transcriptions]))\n",
    "\n",
    "    return transcriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688b5b1-adae-40d3-b951-f79fdee36288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick out a character image based on its position from the automatic transcription\n",
    "# Tries to infer position based on the midpoint between the kraken cuts of this and the previous and following characters.\n",
    "\n",
    "def get_graph_image(line_graphs, g_idx, img, verbose=isVerbose):\n",
    "    g = line_graphs[g_idx]\n",
    "\n",
    "    y_min = g['poly'][0][1]\n",
    "    y_max = g['poly'][1][1]\n",
    "\n",
    "    if g_idx > 0:\n",
    "        x_min = (g['poly'][0][0] + line_graphs[g_idx-1]['poly'][3][0]) // 2\n",
    "    else:\n",
    "        x_min = g['poly'][0][0]\n",
    "\n",
    "    if g_idx < len(line_graphs) - 1:\n",
    "        x_max = (g['poly'][3][0] + line_graphs[g_idx+1]['poly'][0][0]) // 2\n",
    "    else:\n",
    "        x_max = g['poly'][3][0]\n",
    "\n",
    "    x_min -= (x_max - x_min) // 3\n",
    "    x_max += (x_max - x_min) // 3\n",
    "\n",
    "    if verbose:\n",
    "        print(g['c'], x_min, y_min, x_max, y_max)\n",
    "\n",
    "    return img[y_min:y_max, x_min:x_max, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990d8b82-05c4-42ee-a525-144411975359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get all character images from a given set of transcriptions (normally lines from a given page)\n",
    "# Adds the character images to an existing dictionary keyed to the character\n",
    "\n",
    "def get_char_imgs(transcriptions, char_imgs, img, verbose=isVerbose):\n",
    "    \n",
    "    for l in transcriptions:\n",
    "        for idx in range(len(l['graphs'])):\n",
    "            newchar = l['graphs'][idx]['c']\n",
    "            newim = get_graph_image(l['graphs'], idx, img)\n",
    "            \n",
    "            if newchar in char_imgs:\n",
    "                char_imgs[newchar].append(newim)\n",
    "            else:\n",
    "                char_imgs[newchar] = [newim]\n",
    "    return char_imgs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11e4984-889f-4df6-bcd1-12b162cecba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a list of images in a grid with a set number of columns.\n",
    "# Intended to be used for a list of images of letters (graphs), though could be used for any list of images.\n",
    "\n",
    "def plot_chars(imgs, cols=12):\n",
    "    # Number of images\n",
    "    num_images = len(imgs)\n",
    "    \n",
    "    # Determine the number of rows necessary for the given number of images and columns\n",
    "    rows  = num_images // cols + 1\n",
    "    \n",
    "    # Create a figure with subplots\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(cols, rows+1))\n",
    "    \n",
    "    # Flatten the axes array for easy iteration\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    # Iterate over the images and corresponding axes to display each image\n",
    "    # Be careful: we can sometimes have zero-width images\n",
    "    for i in range(num_images):\n",
    "        if (len(imgs[i]) > 0):\n",
    "            axes[i].imshow(imgs[i])\n",
    "            axes[i].axis('off')  # Hide the axis\n",
    "    \n",
    "    # Hide any remaining empty subplots\n",
    "    for j in range(num_images, rows * cols):\n",
    "        axes[j].axis('off')\n",
    "    \n",
    "    # Display the grid of images\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ff0b93-0d84-4e91-a853-ddb51f0b4e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the character images for a given page and store in a dictionary keyed to the character\n",
    "\n",
    "def get_chars_per_page(doc_id, part_id, transcr_id, verbose=isVerbose):\n",
    "    img = get_image(doc_id, part_id)\n",
    "    trans = get_transcriptions(doc_id, part_id, transcr_id)\n",
    "    \n",
    "    char_imgs = {}\n",
    "    return get_char_imgs(trans, char_imgs, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6005159-0def-4fb0-a731-da44f69b34bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of transcriptions and ask the user which one they want\n",
    "# Assume we only have one page of transcriptions.\n",
    "# Only include transcriptions which have an average confidence, assuming that these should be kraken generated.\n",
    "\n",
    "def select_transcription(doc_id):\n",
    "    transcr_list_url = urljoin(base_url, f\"documents/{doc_id}/transcriptions/\")\n",
    "    \n",
    "    transcr_full_list = get_page(transcr_list_url)\n",
    "    transcr_list = [t for t in transcr_full_list if t['avg_confidence']]\n",
    "    \n",
    "    print(\"Please select one of the following transcriptions by numer in the list (0, 2, 3...):\")\n",
    "    for idx in range(len(transcr_list)):\n",
    "        print(f\"  {idx}. {transcr_list[idx]['name']}\")\n",
    "    \n",
    "    trans_idx = int(input(\"\\nTranscription no.\"))\n",
    "    \n",
    "    if trans_idx in list(range(len(transcr_list))):\n",
    "        transcr_id = int(transcr_list[trans_idx]['pk'])\n",
    "        print(f\"Transcription id. {transcr_id} selected\")\n",
    "    else:\n",
    "        transcr_id = None\n",
    "        print(f\"Can't find selected transcript\")\n",
    "\n",
    "    return transcr_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3dae45-959a-44d5-8a36-7ba8fcedc545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the user for the transcription and then get all the graph images for the selected page...\n",
    "\n",
    "transcr_id = select_transcription(doc_id)\n",
    "char_imgs = get_chars_per_page(doc_id, part_id, transcr_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1faabef0-f512-4145-9221-5f4ffc0fe1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ... and show the results\n",
    "\n",
    "plot_chars(char_imgs['s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28d9452-586f-4570-a78c-4a9051da67ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: use get_paged_elements to loop through all the document parts and generate images for the entire document\n",
    "# Storing all the images in memory may be an issue here, so will probably need something more sophisticated for larger documents"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
